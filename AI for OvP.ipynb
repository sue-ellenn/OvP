{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OvP project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43aaeeea5a84e06e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f236473c40224459"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yake\n",
    "# import rake\n",
    "# from rake import RAKE\n",
    "from rake_nltk import Rake\n",
    "from keybert import KeyBERT\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# import openai\n",
    "# from keybert.llm import OpenAI\n",
    "# from keybert import KeyLLM\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "nltk.download('punkt')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# import data\n",
    "data = pd.read_excel(\"raw_data.xlsx\")\n",
    "\n",
    "print(data.head(2))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "73fb4ef954840065",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2e0f74c730bd96"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "print(data.columns)\n",
    "teacher_list_raw = data['DOCENT_ROL'].tolist()\n",
    "print(teacher_list_raw[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "399b7841b1451440",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "teacher_list = [\n",
    "    item.strip()\n",
    "    for entry in teacher_list_raw\n",
    "    for item in entry.split(';')\n",
    "]\n",
    "print(teacher_list[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "f0f4250b0960b3fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choose keyword model by example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a385965ce078a142"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "stop_words_dict = {'eng':stopwords.words('english'), 'nl': stopwords.words('dutch')}",
   "id": "901d671b478316d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "example_text = \"Deze cursus gaat over de visuele cultuur van de Nederlandse zeventiende-eeuwse Republiek. De ongekende commerciÃ«le groei van de Verenigde Nederlanden kwam voort uit expansiedrang en kolonialisme, wat onder meer resulteerde in een bloeiende kunst- en rariteitenhandel en een explosie van artistieke creativiteit. Deze cursus onderzoekt de impact van de steeds groter wordende wereld op de beeldende kunsten. Welke rol speelden kunstwerken en andere exotische kunstobjecten die in de huiselijke sfeer werden verzameld en gekoesterd? Wat werd er afgebeeld, waarom en voor wie? Wat onthullen schilderijen over de houding van de Nederlanders ten opzichte van de koloniÃ«n, van andere Europese landen en van zichzelf? Wat vertellen rariteitenverzamelingen ons over de verhouding tussen het zelf en de wereld, het vertrouwde en het vreemde, het lokale en het internationale? Maar ook zal er stil worden gestaan bij ontdekkingen die op wetenschappelijk gebied worden gedaan en hoe deze al vlug hun weg weten te vinden in de beeldende kunst. [NB: de cursusinhoud is onder voorbehoud en kan wijzigen]\"\n",
    "\n",
    "\n",
    "lang = detect(example_text)\n",
    "\n",
    "# print(f\"Language: {lang} â†’ Stopwords: {stop_words_dict[lang][:5]}\")\n",
    "print(f\"Language: {lang}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "ff813c018222fb85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# yake function\n",
    "def yake_extract_keywords(text, lang='eng'):\n",
    "    kw_extractor = yake.KeywordExtractor(\n",
    "                            lan=lang,           # or appropriate language code\n",
    "                            n=3,                # max n-gram size (try 2-3)\n",
    "                            dedupLim=0.8,       # make deduplication stricter\n",
    "                            dedupFunc='levs',   # try 'levs' or 'jaro' instead of default 'seqm'\n",
    "                            windowsSize=2,      # context window size\n",
    "                            top=15              # how many keywords you want\n",
    "                        )\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw for kw, score in keywords]\n",
    "\n",
    "yake_kw = yake_extract_keywords(example_text, lang)\n",
    "print(\"yake: \", yake_kw)"
   ],
   "id": "d9a856ea8cec651e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def rake_extract_keywords(text, lang='eng'):\n",
    "    # rake = RAKE()\n",
    "    rake = Rake(stopwords=stop_words_dict[lang])\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    return rake.get_ranked_phrases()\n",
    "\n",
    "rake_kw = rake_extract_keywords(example_text, lang)\n",
    "print(\"rake: \", rake_kw)"
   ],
   "id": "90e59999a69db8f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def keybert_extract_keywords(text, lang='eng'):\n",
    "    kw_model = KeyBERT(model=\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "    keywords = kw_model.extract_keywords(\n",
    "                                text,\n",
    "                                keyphrase_ngram_range=(1,4),\n",
    "                                stop_words=stop_words_dict[lang],\n",
    "                                use_maxsum=True,\n",
    "                                # nr_candidates=20,\n",
    "                                top_n=20,\n",
    "                                use_mmr=True,\n",
    "                                diversity=0.9,\n",
    "                                highlight=True\n",
    "    )\n",
    "    return keywords\n",
    "\n",
    "keybert_kw = keybert_extract_keywords(example_text, lang)\n",
    "print(\"keybert: \", keybert_kw)"
   ],
   "id": "8ce58d872e7d5a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# chatGPT generated\n",
    "\n",
    "def extract_keywords_advanced(text, top_n=20):\n",
    "\n",
    "    # model dat NL + EN begrijpt\n",
    "    kw_model = KeyBERT(model=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "    # tekst splitsen in zinnen\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    all_keywords = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        # per zin keywords halen\n",
    "        kw = kw_model.extract_keywords(\n",
    "            sent,\n",
    "            keyphrase_ngram_range=(1, 3),\n",
    "            stop_words=stop_words_dict[lang],\n",
    "            use_mmr=True,\n",
    "            diversity=0.7,\n",
    "            top_n=5\n",
    "        )\n",
    "        all_keywords.extend([k for k, _ in kw])\n",
    "\n",
    "    # opschonen en unieke termen behouden\n",
    "    cleaned = []\n",
    "    for kw in all_keywords:\n",
    "        kw = kw.lower().strip()\n",
    "        kw = re.sub(r'[^a-zÃ -Ã¿0-9\\s\\-]', '', kw)  # speciale tekens eruit\n",
    "        if len(kw.split()) > 1 and kw not in cleaned:  # liever zinnen dan losse woorden\n",
    "            cleaned.append(kw)\n",
    "\n",
    "    # top_n beperken\n",
    "    cleaned = cleaned[:top_n]\n",
    "\n",
    "    return {\n",
    "        \"language_detected\": lang,\n",
    "        \"keywords\": cleaned\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3ï¸âƒ£ Test\n",
    "# -------------------------------------------------\n",
    "\n",
    "results = extract_keywords_advanced(example_text, top_n=20)\n",
    "\n",
    "print(f\"ðŸ—£ï¸ Detected language: {results['language_detected']}\")\n",
    "print(\"ðŸŽ¯ Top keywords:\")\n",
    "for kw in results[\"keywords\"]:\n",
    "    print(\"-\", kw)\n"
   ],
   "id": "6cbebeea9af88ce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get keywords per topic\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5ea78e4e43b1354"
  },
  {
   "cell_type": "code",
   "source": [
    "course_dict = {}\n",
    "\n",
    "for ind, row in data.iterrows():\n",
    "    # print(row)\n",
    "    # print(\"done: \",row[0], row[1], row[2])\n",
    "    course_code, course_name, teachers, keywords = row\n",
    "    if pd.isna(keywords):\n",
    "        continue\n",
    "        \n",
    "    teachers = teachers.split(\";\")\n",
    "    teachers = list(set([' '.join(item.split()[:-1]) for item in teachers]))\n",
    "    \n",
    "    # using yake, keywords not great\n",
    "    keywords_yake = yake_extract_keywords(keywords)\n",
    "    \n",
    "    # use keybert, slightly better but not perfect yet\n",
    "    kw_model = KeyBERT()\n",
    "    keywords_bert = kw_model.extract_keywords(keywords,\n",
    "                                              stop_words='english',\n",
    "                                              use_maxsum=True,\n",
    "                                              nr_candidates=20,\n",
    "                                              top_n=20, \n",
    "                                              keyphrase_ngram_range=(1, 3),\n",
    "                                              use_mmr=True,\n",
    "                                              diversity=0.7)\n",
    "    # print(keywords)\n",
    "    \n",
    "    course_dict[row[0]] = {\"course_code\": course_code,\n",
    "                           \"course_name\": course_name,\n",
    "                           \"teachers\": teachers,\n",
    "                           \"keywords_yake\": keywords_yake,\n",
    "                           \"keywords_bert\": keywords_bert}\n",
    "    break\n",
    "    \n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(course_dict)\n",
    "    # if ind > 3:\n",
    "    #     break"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "e9487896c07cea34",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "b19d8a56570c0a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try using LLM API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "945ac777b687fc67"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "3f86cc27cba47b2f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
