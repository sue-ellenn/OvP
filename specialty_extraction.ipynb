{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OvP project\n",
   "id": "d286604abd2323e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and data loading",
   "id": "17aebcc5ca3e216d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-27T20:51:30.708356Z",
     "start_time": "2025-10-27T20:51:30.639126Z"
    }
   },
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yake\n",
    "# import rake\n",
    "# from rake import RAKE\n",
    "# from rake_nltk import Rake\n",
    "# from keybert import KeyBERT\n",
    "# from langdetect import detect\n",
    "# import nltk\n",
    "# import re\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "# \n",
    "# import spacy\n",
    "# import keyword_spacy\n",
    "# from keyword_spacy import KeywordExtractor\n",
    "\n",
    "# import openai\n",
    "from keybert.llm import OpenAI\n",
    "from keybert import KeyLLM\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('punkt')\n",
    "import transformers\n",
    "from transformers import pipeline"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:48:33.620051Z",
     "start_time": "2025-10-23T14:48:33.610114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f = open(\"C:\\\\Users\\sue-e\\Downloads\\openAI API key.txt\")\n",
    "GPT_API_KEY = f.read()\n",
    "f.close()"
   ],
   "id": "67015b43746b800",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Osiris excel data",
   "id": "b838e0fe2f996c07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T20:51:37.746842Z",
     "start_time": "2025-10-27T20:51:36.977166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import data\n",
    "data = pd.read_excel(\"raw_data.xlsx\")\n",
    "\n",
    "data.head(2)"
   ],
   "id": "612a86cdbd330669",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        CURSUS             LANGE_NAAM_NL  \\\n",
       "0   ASB-ACT-EN  ACT - Leef zoals je wilt   \n",
       "1  ASB-ACTLEEF  ACT - Leef zoals je wilt   \n",
       "\n",
       "                                          DOCENT_ROL  \\\n",
       "0  Brasjen DOCENT; Bruinsma DOCENT; Buiks DOCENT;...   \n",
       "1  Brasjen DOCENT; Bruinsma DOCENT; Buiks DOCENT;...   \n",
       "\n",
       "  OSS_ADF_UTILITY.HTML_TO_TEXT(H.INHOUD) Aims  \n",
       "0                                    NaN  NaN  \n",
       "1                                    NaN  NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURSUS</th>\n",
       "      <th>LANGE_NAAM_NL</th>\n",
       "      <th>DOCENT_ROL</th>\n",
       "      <th>OSS_ADF_UTILITY.HTML_TO_TEXT(H.INHOUD)</th>\n",
       "      <th>Aims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASB-ACT-EN</td>\n",
       "      <td>ACT - Leef zoals je wilt</td>\n",
       "      <td>Brasjen DOCENT; Bruinsma DOCENT; Buiks DOCENT;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASB-ACTLEEF</td>\n",
       "      <td>ACT - Leef zoals je wilt</td>\n",
       "      <td>Brasjen DOCENT; Bruinsma DOCENT; Buiks DOCENT;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T20:51:45.584371Z",
     "start_time": "2025-10-27T20:51:45.527461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# format teachers\n",
    "\n",
    "def format_teachers(row):\n",
    "    teachers = row['DOCENT_ROL']\n",
    "    # 'Brasjen DOCENT; Bruinsma DOCENT; Buiks DOCENT; Burgh DOCENT; Galipò DOCENT; Gronden DOCENT; Kaathoven CONTACTPERSOON; Verhagen DOCENT'\n",
    "    \n",
    "    formatted_list = []\n",
    "    \n",
    "    \n",
    "    teachers = teachers.split(\";\")\n",
    "    roles= ['DOCENT', 'TEACHER', 'EXAMINATOR', 'EXAMINER']\n",
    "    \n",
    "    for teach in teachers:\n",
    "        t = teach.split()\n",
    "        \n",
    "        if t[-1] in roles:\n",
    "            formatted_list.extend(t[:-1])\n",
    "            \n",
    "    delimiter = \"; \" # Define a delimiter\n",
    "    join_str = delimiter.join(formatted_list)\n",
    "    return join_str\n",
    "\n",
    "data['DOCENT_ROL'] = data.apply(format_teachers, axis=1)\n",
    "\n",
    "data.head(2)"
   ],
   "id": "ff17914656817e90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        CURSUS             LANGE_NAAM_NL  \\\n",
       "0   ASB-ACT-EN  ACT - Leef zoals je wilt   \n",
       "1  ASB-ACTLEEF  ACT - Leef zoals je wilt   \n",
       "\n",
       "                                          DOCENT_ROL  \\\n",
       "0  Brasjen; Bruinsma; Buiks; Burgh; Galipò; Grond...   \n",
       "1  Brasjen; Bruinsma; Buiks; Burgh; Galipò; Grond...   \n",
       "\n",
       "  OSS_ADF_UTILITY.HTML_TO_TEXT(H.INHOUD) Aims  \n",
       "0                                    NaN  NaN  \n",
       "1                                    NaN  NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURSUS</th>\n",
       "      <th>LANGE_NAAM_NL</th>\n",
       "      <th>DOCENT_ROL</th>\n",
       "      <th>OSS_ADF_UTILITY.HTML_TO_TEXT(H.INHOUD)</th>\n",
       "      <th>Aims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASB-ACT-EN</td>\n",
       "      <td>ACT - Leef zoals je wilt</td>\n",
       "      <td>Brasjen; Bruinsma; Buiks; Burgh; Galipò; Grond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASB-ACTLEEF</td>\n",
       "      <td>ACT - Leef zoals je wilt</td>\n",
       "      <td>Brasjen; Bruinsma; Buiks; Burgh; Galipò; Grond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:48:34.760739Z",
     "start_time": "2025-10-23T14:48:34.751699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OG_data = data.copy()\n",
    "small_data = data.iloc[29995:3000]"
   ],
   "id": "4639f07c3307d26a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipeline creation for specialty extraction",
   "id": "418653016dad5597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:48:36.487686Z",
     "start_time": "2025-10-23T14:48:34.762752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model\n",
    "# extractor = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "extractor = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "\n",
    "# Define your extraction function\n",
    "def extract_specialty(row):\n",
    "    prompt = f\"\"\"\n",
    "    You are an academic data extractor.\n",
    "\n",
    "    From the following course metadata, identify the teacher's likely area of academic specialization. Use the course aims primarily.\n",
    "    Focus on the academic field or topic expertise (max 7 words).\n",
    "    All teachers in the same course get the same specialty added.\n",
    "    If there is no course description or if the course description is nan, extract the teachers but make their specialty blank. \n",
    "\n",
    "    Return JSON with keys: name, specialty.\n",
    "\n",
    "    Course code: {row['CURSUS']}\n",
    "    Course name: {row['LANGE_NAAM_NL']}\n",
    "    Teacher and role: {row['DOCENT_ROL']}\n",
    "    Course description: {row['OSS_ADF_UTILITY.HTML_TO_TEXT(H.INHOUD)']}\n",
    "    Course aims: {row['Aims']}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        result = extractor(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
    "        # print(result)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"\\nFAIl\")\n",
    "        return str(e)"
   ],
   "id": "b656be270525191c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bc61de801074715b32c47ac0b3cea52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:53:21.803927Z",
     "start_time": "2025-10-23T14:48:36.489698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test case\n",
    "new_data = extract_specialty(data.iloc[2998])\n",
    "print(new_data)"
   ],
   "id": "228d3f4f306ff343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are an academic data extractor.\n",
      "\n",
      "    From the following course metadata, identify the teacher's likely area of academic specialization. Use the course aims primarily.\n",
      "    Focus on the academic field or topic expertise (max 7 words).\n",
      "    All teachers in the same course get the same specialty added.\n",
      "    If there is no course description or if the course description is nan, extract the teachers but make their specialty blank. \n",
      "\n",
      "    Return JSON with keys: name, specialty.\n",
      "\n",
      "    Course code: SOW-BKI323\n",
      "    Course name: Brain-Computer Interfacing\n",
      "    Teacher and role: Tangermann; Thielen\n",
      "    Course description: Content\n",
      "What the course is about: This course is centered around the data analysis pipelines typically found in brain-computer interfaces: the processing of multi-channel recordings of neuronal signals, the extraction of informative features (“neural markers”) from these signals, and the decoding of brain states by regression or classification models. As informative features are subject-dependent, and as neuronal signals typically show large dimensionality, high noise, and low signal amplitudes, machine learning methods play an important role in all steps of the pipeline. Thus we have to assume from course participants three important skills:\n",
      " \n",
      "- sound mathematical background to understand the statistical methods and machine learning algorithms dealt with in the course (mainly probability theory and linear algebra). Please expect, that this will go into the math foundations of methods and not stay superficial.\n",
      " \n",
      "- familiarity with machine learning concepts, data handling, and model evaluation strategies.\n",
      " \n",
      "- the ability to implement these in Python.\n",
      "Word of caution: please note that if a participant lacks these assumed skills / background, the successful completion of the course may be very difficult and exceed the expected workload for a 6 ECTS course substantially. \n",
      "What the course is not about: The course will be able to cover and train the ability to perform offline analyses. We try to include hands-on experience with an online / closed-loop BCI system. How feasible this is will depend on the size of the course.\n",
      "The course covers a selection of data processing methods relevant for the most widely used BCI applications. However, the course can neither cover the full spectrum of neurotechnological applications nor the large number of different processing algorithms proposed in the literature. To cover the curriculum, familiarity with mathematical concepts like dot products, matrix/vector calculations, matrix inversion, covariance matrix, eigenvalue decomposition, Bayes theorem, basic probability theory, etc. needs to be assumed and can not be taught in this course. The course will also assume, that students are familiar with basic signal processing methods taught in BKI316 (Fourier transform, Hilbert transform, filtering of time series data in the time- and frequency domain) and their mathematical background.\n",
      "The course will focus on processing methods applicable for invasive mesoscopic (local field potentials “LFP”, electrocorticogram “ECoG”) and non-invasive macroscopic (electroencephalogram “EEG”, magnetoencephalogram “MEG”) electromagnetic signals, while the processing of action potentials / single-unit activity and the analysis of functional MRI and functional near-infrared signal data cannot be covered in this course.\n",
      "While neurotechnological systems may combine neural recordings with signals of non-neural origin (electromyogram “EMG”, body tracking, behavioral performance recordings by accelerometers, etc.), the course will have to focus on neural signals.\n",
      "While developing a successful BCI / neurotechnological system is a highly interdisciplinary endeavor that profits from the collaboration of neuroscientists, psychologists, signal processing- and artificial intelligence specialists, this course will put the most emphasis on the latter two aspects.\n",
      "    Course aims: A brain-computer interface (BCI) typically is a closed-loop system. Its core characteristic is, that it allows to extract information about a person’s brain state from his/her ongoing neural signals. This information is very valuable in neurotechnological applications. Examples thereof are the control of software applications (e.g., for communication in patients whose motor control and language is impaired, or for gaming), to control external physical devices (e.g., a robotic arm, or a wheel chair), to support basic neuroscience research with closed-loop experimental paradigms, to realize novel brain-state dependent rehabilitation protocols after stroke, to monitor the attention and workload state of a subject, to monitor the progress of a patient, to realize a closed-loop adaptive deep brain stimulation system for patients with Parkinson’s disease, to detect epileptic seizures and counter them with cortical electrical stimulation etc.\n",
      "\n",
      "Overall, the course prepares students for a Bachelor project/thesis in the field of neurotechnological systems / BCI and is an excellent basis to study advanced brain signal decoding methods and closed-loop neurotechnological systems in a Master program.\n",
      "\n",
      "Upon successful completion of the course, the student will:\n",
      "know the characteristics of (mainly electrical) brain signal data recordings;\n",
      "understand how a brain-computer interface (BCI) works, its limitations, and how two signal phenomena observed in magnetic and electric neural signals (transiently evoked event-related potentials and changes of oscillatory activity) can be transformed into practical BCI systems;\n",
      "have a theoretical understanding of the most important basic modules used in the BCI data analysis pipelines of the two signal phenomena (signal preprocessing, feature extraction, and decoding via classification / regression models);\n",
      "have practical skills to implement and use these basic modules in a Python-based programming framework with given neuronal data;\n",
      "have learned approaches to evaluate/benchmark novel preprocessing and decoding algorithms in offline analyses;\n",
      "understand the challenge of non-stationarity in neuronal data and know, how this can be tackled;\n",
      "understand, how neurotechnological data analysis problems and specifically time series data differ from typical mainstream machine learning problems, e.g., image processing.\n",
      "    \n",
      "Please note: \n",
      "\n",
      "- While the course is based on the state-of-the-art of the field, it does not cover the entire spectrum of neurotechnological applications and the large number of different processing algorithms proposed in the literature.\n",
      "- The course will cover neurotechnological applications that are based on invasive mesoscopic (local field potentials “LFP”, electrocorticogram “ECoG”) and non-invasive macro\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-23T14:53:21.810081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_data = extract_specialty(data.iloc[2999])\n",
    "print(new_data)"
   ],
   "id": "e3670ef7671c7d10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# small datset\n",
    "small_data[\"structured_info\"] = small_data.apply(extract_specialty, axis=1)\n",
    "\n",
    "small_data.to_excel(\"created_data/teachers_with_specialties_local.xlsx\", index=True)\n"
   ],
   "id": "a1ce4c71ac4d2914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(\"done\")",
   "id": "13835cad51f91f54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Word document",
   "id": "500d20e17a929e5e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# from spire.doc import *\n",
    "# from spire.doc.common import *\n",
    "from docx import Document"
   ],
   "id": "d6dac4e4ee985df0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# spire lib\n",
    "# doc = Document()\n",
    "# doc.LoadFromFile(\"Radboud AI - samenvatting - activiteiten en groepen.docx\")\n",
    "# \n",
    "# builtinProperties = doc.BuiltinDocumentProperties\n",
    "\n",
    "# properties = [\n",
    "#     \"Author: \" + builtinProperties.Author,\n",
    "#     \"Company: \" + builtinProperties.Company,\n",
    "#     \"Title: \" + builtinProperties.Title,\n",
    "#     \"Subject: \" + builtinProperties.Subject,\n",
    "#     \"Keywords: \" + builtinProperties.Keywords,\n",
    "#     \"Category: \" + builtinProperties.Category,\n",
    "#     \"Manager: \" + builtinProperties.Manager,\n",
    "#     \"Comments: \" + builtinProperties.Comments,\n",
    "#     \"Hyperlink Base: \" + builtinProperties.HyperLinkBase,\n",
    "#     \"Word Count: \" + str(builtinProperties.WordCount),\n",
    "#     \"Page Count: \" + str(builtinProperties.PageCount),\n",
    "# ]\n",
    "# \n",
    "# for i in range(0, len(properties)):\n",
    "#     print(properties[i])"
   ],
   "id": "485a6d46f33e50f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# # Iterate through the sections\n",
    "# for i in range(doc.Sections.Count):\n",
    "#     # Get a specific section\n",
    "#     section = doc.Sections.get_Item(i)\n",
    "# \n",
    "#     # Get tables from the section\n",
    "#     tables = section.Tables\n",
    "# \n",
    "#     # Iterate through the tables\n",
    "#     for j in range(0, tables.Count):\n",
    "# \n",
    "#         # Get a certain table\n",
    "#         table = tables.get_Item(j)\n",
    "# \n",
    "#         # Declare a variable to store the table data\n",
    "#         tableData = \"\"\n",
    "# \n",
    "#         # Iterate through the rows of the table\n",
    "#         for m in range(0, table.Rows.Count):\n",
    "# \n",
    "#             # Iterate through the cells of the row\n",
    "#             for n in range(0, table.Rows.get_Item(m).Cells.Count):\n",
    "# \n",
    "#                 # Get a cell\n",
    "#                 cell = table.Rows.get_Item(m).Cells.get_Item(n)\n",
    "# \n",
    "#                 # Get the text in the cell\n",
    "#                 cellText = \"\"\n",
    "#                 for para in range(cell.Paragraphs.Count):\n",
    "#                     paragraphText = cell.Paragraphs.get_Item(para).Text\n",
    "#                     cellText += (paragraphText + \"     \")\n",
    "# \n",
    "#                 # Add the text to the string\n",
    "#                 tableData += cellText\n",
    "# \n",
    "#             # Add a new line\n",
    "#             tableData += \"\\n\"\n",
    "#     \n",
    "#         # Save the table data to a text file\n",
    "#         try:\n",
    "#             with open(f\"output/WordTable_{i+1}_{j+1}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(tableData)\n",
    "#                 f.close()\n",
    "#         except:\n",
    "#             print(\"FAIl\")"
   ],
   "id": "25091cca8d1c47a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# text = doc.GetText()\n",
    "# \n",
    "# print(text)"
   ],
   "id": "cc0358e00b3a735f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Python-docx library",
   "id": "6c11ec0104c1e13"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "doc = Document(\"Radboud AI - samenvatting - activiteiten en groepen.docx\")\n",
    "\n",
    "for t, table in enumerate(doc.tables):\n",
    "    print(f\"--- Tabel {t+1} ---\")\n",
    "    for row in table.rows:\n",
    "        cells = [cell.text.strip() for cell in row.cells]\n",
    "        print(cells)"
   ],
   "id": "2da003d02245b616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ff64b9dbac60e133"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## webscraper tutorials\n",
    "\n",
    "-  https://medium.com/@joerosborne/intro-to-web-scraping-build-your-first-scraper-in-5-minutes-1c36b5c4b110\n",
    "- https://medium.com/@joerosborne/web-scraping-with-puppeteer-extra-typescript-aws-lambda-bf4f49d49806\n"
   ],
   "id": "7f4a66a42e48fbae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
